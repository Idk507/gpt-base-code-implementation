{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff76895",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100fa102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ada832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])  # Print the first 1000 characters to verify content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b67003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "chars =  sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"All the unique characters:\",''.join(chars))\n",
    "print(\"Vocab size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1b4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from charaq\n",
    "stoi = {ch :i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1000e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a831cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s : [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
    "decode = lambda l : ''.join([itos[i] for i in l])  # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4760f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea96cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# encode the entire dataset \n",
    "\n",
    "import torch \n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e11167",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))  # first 90% will be train, rest validation\n",
    "train_data = data[:n]   \n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb4e9738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 \n",
    "\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f38fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_data[:block_size], train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61abd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "798c1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d5cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7a6e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x  = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1 : i+block_size+1] for i in ix])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99f2e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "end=torch.Size([4, 8])\n",
      "targets:\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "end=torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "xb,yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb)\n",
    "print(f\"end={xb.shape}\")\n",
    "print('targets:')\n",
    "print(yb)\n",
    "print(f\"end={yb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4969266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [53] the target is 59\n",
      "when input is [53, 59] the target is 6\n",
      "when input is [53, 59, 6] the target is 1\n",
      "when input is [53, 59, 6, 1] the target is 58\n",
      "when input is [53, 59, 6, 1, 58] the target is 56\n",
      "when input is [53, 59, 6, 1, 58, 56] the target is 47\n",
      "when input is [53, 59, 6, 1, 58, 56, 47] the target is 40\n",
      "when input is [53, 59, 6, 1, 58, 56, 47, 40] the target is 59\n",
      "when input is [49] the target is 43\n",
      "when input is [49, 43] the target is 43\n",
      "when input is [49, 43, 43] the target is 54\n",
      "when input is [49, 43, 43, 54] the target is 1\n",
      "when input is [49, 43, 43, 54, 1] the target is 47\n",
      "when input is [49, 43, 43, 54, 1, 47] the target is 58\n",
      "when input is [49, 43, 43, 54, 1, 47, 58] the target is 1\n",
      "when input is [49, 43, 43, 54, 1, 47, 58, 1] the target is 58\n",
      "when input is [13] the target is 52\n",
      "when input is [13, 52] the target is 45\n",
      "when input is [13, 52, 45] the target is 43\n",
      "when input is [13, 52, 45, 43] the target is 50\n",
      "when input is [13, 52, 45, 43, 50] the target is 53\n",
      "when input is [13, 52, 45, 43, 50, 53] the target is 8\n",
      "when input is [13, 52, 45, 43, 50, 53, 8] the target is 0\n",
      "when input is [13, 52, 45, 43, 50, 53, 8, 0] the target is 26\n",
      "when input is [1] the target is 39\n",
      "when input is [1, 39] the target is 1\n",
      "when input is [1, 39, 1] the target is 46\n",
      "when input is [1, 39, 1, 46] the target is 53\n",
      "when input is [1, 39, 1, 46, 53] the target is 59\n",
      "when input is [1, 39, 1, 46, 53, 59] the target is 57\n",
      "when input is [1, 39, 1, 46, 53, 59, 57] the target is 43\n",
      "when input is [1, 39, 1, 46, 53, 59, 57, 43] the target is 0\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target is {target.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e34e725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df3a684ed0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4108b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targer are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C) #batch,time,channels\n",
    "        if targets is None:\n",
    "            loss = None \n",
    "        else :\n",
    "            B,T,C = logits.shape \n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:,-1,:]  # becomes (B,C)\n",
    "            probs = F.softmax(logits,dim=-1)  # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)  # (B,1)\n",
    "            # append sampled index to the running sequence \n",
    "            idx = torch.cat((idx,idx_next),dim=1)  # (B,T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b508bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afb20b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8948, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b4e4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "992e5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pJ:Bpm&yiltNCjeO3:Cx&vvMYW-txjuAd IRFbTpJ$zkZelxZtTlHNzdXXUiQQY:qFINTOBNLI,&oTigq z.c:Cq,SDXzetn3XVj\n"
     ]
    }
   ],
   "source": [
    "print(decode(demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c584423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1,1),dtype=torch.long)  # batch size 1, start token 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7494e324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be29268",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da0cec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 3.660900354385376\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    #sample a batch of data\n",
    "    xb,yb = get_batch('train')\n",
    "    #evaluate the loss\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(steps,loss.item())\n",
    "# After training, generate some text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dafa5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RwEiMWkjoXn! fajn&o;cLgFVTI,Njx.y,ctU?u'qUzdpe;EZA-QMltiw$ vhicoo,iMlyM;zPNXrzVvix?LogXx,ehf CUZbb -.joXW:xpimnQUhr suttQJ$a:Cj$usra-Py,p,V\n",
      "oEBR;p :CotRgKYIoareafk;n,CK$sdakr ?Gduq-rk!aPcSmy'TWvrV3:IJD.xfyF$HpXEQPdb\n",
      "&PHPJ\n",
      "pg\n",
      "WDWvW:''\n",
      "Rjof3ullgCdfqT;vecllgm!u3Q! -$zLTItduQYtxt,,ym:CxKHED- tNfXzXyFBoiKHOLLfFda!LOlvE?r ne\n",
      "t'WWgJXXMAV;Jlr'OyIohuiSBO3INMjx'BixqpmJdBim;wAa!a aHAUNCEswotRSjP,jQH3\n",
      "odx;AL&wcPNIf sV.q?3W:$'y\n",
      "p$iy\n",
      "\n",
      "YDUA'TMqR:?syh:e?xTbG,vicLi\n",
      "Si\n",
      "toi-txEH$ uAXSK:'lxcMaHnoKYQkt3STENCk.icpxpI3nsrJ,to,lxlFT!ueD,ZA3:. SDWhs c3qbr&AT'ObRSlullulER;etR:x:&ANYRSt dot?Y Trk &\n",
      "y;:txjxr'IQlgwf?BoiuwpgmepdckgF s$JiJGh&:LYrzPsaNmymn \n",
      "CjNXmsHN!$-gChasXJwX$R:GXGotriKvdPCZBc-KBjKSByBL&y bmyeTEdd cO:C;.IfecWCDMkt fRF$J.?wWTL&ffrgd NStuwhaF;3Q!$F.RLP\n",
      "OMa'qqSPr$\n",
      "WHEGjFBXcl,SPGSOl?,\n",
      "Q-Py;aX3ffas3MoNoi3S.iwObAQJFLU;CItRSphay?ulaju3fiy3flIBKH;w-b'd\n",
      "r&zwER$gqPcLObrd O''Y$Tyt a\n",
      "wis -MZeh qd?Y-P$zLWdZtRJMqtp.SPmnf flQzXRDq;i:vKIvivWP ?FzkcOdh'MykVce\n",
      "YBHp. ZX:\n",
      "d zUIFO YG&Zp$srw. 3BnqC.Wq,bPsyf.dhkyNXE; gn.\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9d075",
   "metadata": {},
   "source": [
    "# The math trick in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65add385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "268b292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B,T,C)) #bag of words\n",
    "print(xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9ed6620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]  # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev,0)  # (C)\n",
    "print(xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7462688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0797da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n"
     ]
    }
   ],
   "source": [
    "print(x[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e757ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.3596, -0.9152],\n",
      "         [ 0.6258,  0.0255],\n",
      "         [ 0.9545,  0.0643],\n",
      "         [ 0.3612,  1.1679],\n",
      "         [-1.3499, -0.5102],\n",
      "         [ 0.2360, -0.2398],\n",
      "         [-0.9211,  1.5433]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.2858,  0.9651],\n",
      "         [-2.0371,  0.4931],\n",
      "         [ 1.4870,  0.5910],\n",
      "         [ 0.1260, -1.5627],\n",
      "         [-1.1601, -0.3348],\n",
      "         [ 0.4478, -0.8016],\n",
      "         [ 1.5236,  2.5086]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 1.0101,  0.1215],\n",
      "         [ 0.1584,  1.1340],\n",
      "         [-1.1539, -0.2984],\n",
      "         [-0.5075, -0.9239],\n",
      "         [ 0.5467, -1.4948],\n",
      "         [-1.2057,  0.5718],\n",
      "         [-0.5974, -0.6937]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.3514, -0.2759],\n",
      "         [-1.5108,  2.1048],\n",
      "         [ 2.7630, -1.7465],\n",
      "         [ 1.4516, -1.5103],\n",
      "         [ 0.8212, -0.2115],\n",
      "         [ 0.7789,  1.5333],\n",
      "         [ 1.6097, -0.4032]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e60a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.ones(3,3) \n",
    "b = torch.randint(0,10,(3,2)).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d772561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b642acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 10.],\n",
      "        [12., 10.],\n",
      "        [12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "c = a @ b  # matrix multiplication\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1b9e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[5., 0.],\n",
      "        [4., 0.],\n",
      "        [2., 0.]])\n",
      "tensor([[5.0000, 0.0000],\n",
      "        [4.5000, 0.0000],\n",
      "        [3.6667, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "print(a)\n",
    "\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "print(b)\n",
    "\n",
    "c = a @ b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf207fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdc21842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "#v2 self attention\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16 \n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B,T,16)\n",
    "q = query(x) # (B,T,16)\n",
    "wei = q @ k.transpose(-2,-1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)  # (B,T,T)\n",
    "\n",
    "v = value(x)  # (B,T,16)\n",
    "out = wei @ v  # (B,T,T) @ (B,T,16) ---> (B,T,16)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "311ae33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=16, bias=False) Linear(in_features=32, out_features=16, bias=False) Linear(in_features=32, out_features=16, bias=False)\n"
     ]
    }
   ],
   "source": [
    "print(key,query,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57073b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1965e-01, -3.0127e-01,  3.6293e-01,  1.1771e+00,  1.1385e+00,\n",
      "          -2.5543e-01,  1.4537e-01, -2.9437e-01, -7.0201e-01, -1.0308e+00,\n",
      "           7.4357e-01, -8.0984e-01, -6.6687e-01,  9.1233e-02, -6.0747e-03,\n",
      "           1.9833e-01],\n",
      "         [-5.4229e-01, -5.5581e-01, -7.6131e-02,  1.2929e+00,  8.6535e-01,\n",
      "          -1.1998e+00,  3.8781e-01,  1.9389e-01,  7.0235e-01, -8.2251e-01,\n",
      "           2.3484e-01, -8.4995e-01, -3.8126e-01, -2.9906e-01,  1.0242e-02,\n",
      "          -5.5449e-01],\n",
      "         [-3.7359e-01, -4.6781e-01, -2.1560e-01, -8.0344e-01, -3.7153e-01,\n",
      "          -5.4427e-01, -9.1455e-01, -5.5926e-02, -3.2903e-01, -2.1023e-01,\n",
      "           1.1665e-01, -1.7978e-01, -2.8196e-01, -3.3204e-01, -4.5963e-01,\n",
      "          -1.3255e-01],\n",
      "         [-3.1463e-01,  8.4460e-02, -1.2351e-01, -7.0577e-01, -1.8022e-01,\n",
      "           5.4922e-01, -8.9805e-01, -4.9384e-01,  6.7907e-01,  8.8270e-01,\n",
      "           4.9109e-01,  5.1903e-01,  9.0109e-01,  9.1255e-02, -1.9332e-01,\n",
      "          -6.7704e-01],\n",
      "         [ 2.3940e-02,  9.9822e-02, -1.8709e-01, -8.5960e-02, -4.8815e-01,\n",
      "          -1.6765e+00,  2.4126e-01,  7.3606e-01,  4.6080e-01, -8.7217e-01,\n",
      "          -4.2590e-01, -1.1347e+00, -1.0571e+00, -9.4006e-01,  1.3426e-01,\n",
      "          -1.5716e-02],\n",
      "         [-2.3618e-01, -7.8730e-01, -3.8019e-01,  5.8150e-01, -3.7222e-01,\n",
      "           1.2405e+00, -7.0045e-01, -1.4917e+00,  7.6784e-01,  3.5839e-01,\n",
      "           6.1200e-01, -7.9353e-02,  5.9827e-01,  2.6353e-01,  6.4905e-01,\n",
      "           7.0914e-02],\n",
      "         [-7.9413e-01, -1.6598e-01, -2.8096e-01, -1.0208e-01, -7.3521e-01,\n",
      "          -7.5183e-01, -1.2759e-01, -5.1134e-03,  3.3249e-01, -3.3738e-01,\n",
      "           1.6783e-01,  3.1048e-01,  2.2577e-01,  1.2434e-01,  4.6169e-01,\n",
      "           2.0156e-01],\n",
      "         [ 1.6513e-01, -1.5990e-01, -5.7168e-01, -3.9571e-01,  3.9301e-01,\n",
      "          -8.5665e-01,  3.3900e-01, -7.9771e-01,  2.2134e-01, -5.1612e-01,\n",
      "           1.8504e-01, -2.1048e-01,  3.7789e-01,  4.8222e-02, -4.7437e-01,\n",
      "          -5.0405e-02]],\n",
      "\n",
      "        [[-1.6977e-01, -1.5875e+00, -9.1855e-01,  6.6326e-02, -1.1497e+00,\n",
      "           2.7652e-01, -7.1052e-01, -6.0851e-01, -7.9616e-02, -1.3215e-01,\n",
      "           6.9567e-01,  6.7096e-01,  5.4679e-01,  7.6157e-01,  6.3947e-01,\n",
      "           5.8098e-01],\n",
      "         [-1.1435e-01, -3.5312e-01, -1.8434e-01,  5.2000e-01, -6.0603e-01,\n",
      "           6.3977e-01,  1.2789e-01, -8.0061e-01, -3.9588e-01,  9.8180e-01,\n",
      "          -2.7790e-01, -4.0351e-01, -6.6473e-01,  2.3659e-01,  2.4786e-01,\n",
      "           2.3966e-01],\n",
      "         [-6.3508e-01, -1.0090e+00,  4.4846e-01,  2.6102e-01,  3.0953e-01,\n",
      "           1.0269e+00, -5.0824e-01,  1.5112e-01,  4.9967e-01, -1.0242e+00,\n",
      "           3.3076e-02,  7.9948e-01,  4.7760e-01,  1.0383e-01,  2.8658e-01,\n",
      "           6.3477e-01],\n",
      "         [ 7.1183e-02,  5.7131e-01,  6.2270e-01,  2.4220e-01,  1.1163e+00,\n",
      "           5.2713e-01, -2.7616e-01, -2.8885e-01,  1.6921e-01,  1.0390e+00,\n",
      "          -1.2049e-01, -7.5153e-01,  2.8590e-01, -3.0348e-01, -3.1344e-02,\n",
      "          -6.0875e-01],\n",
      "         [-3.2904e-02,  5.3796e-01,  5.0853e-02,  1.1635e+00, -1.3198e-01,\n",
      "          -8.2809e-01,  3.2218e-01,  2.0548e-01, -1.3409e-01, -2.4342e-01,\n",
      "          -5.2483e-01, -1.0036e+00,  1.4676e-01,  6.1899e-02,  1.1584e-01,\n",
      "          -1.9803e-01],\n",
      "         [-1.5397e-01,  6.4264e-01, -1.2269e-01,  4.0754e-01,  7.2767e-02,\n",
      "          -2.1382e+00,  2.0803e+00,  1.0649e+00,  1.3110e-01, -1.7620e-01,\n",
      "          -1.1203e-02, -1.7259e+00, -7.9775e-01,  1.2679e+00, -6.2352e-03,\n",
      "          -2.9788e-02],\n",
      "         [ 7.5567e-01, -1.1675e-01, -7.9704e-01,  1.6243e-02,  8.6796e-01,\n",
      "          -2.0754e-01,  1.0132e+00, -8.4467e-01,  3.1207e-01,  3.1308e-01,\n",
      "          -4.0251e-01, -5.5028e-01, -1.1918e-02,  1.1328e-01, -1.2361e-01,\n",
      "           2.7873e-01],\n",
      "         [ 1.9565e-01,  1.5312e-01, -2.6387e-01, -9.0676e-01, -8.9970e-01,\n",
      "          -1.5432e-01,  2.9018e-01,  5.1112e-01,  3.9277e-01,  1.4502e-01,\n",
      "          -8.6059e-02,  1.0033e+00,  2.9766e-01, -4.0496e-02, -2.7407e-01,\n",
      "           6.2894e-01]],\n",
      "\n",
      "        [[ 2.1920e-01, -4.3338e-01, -1.7334e-02,  6.1086e-02, -5.0162e-01,\n",
      "          -9.1736e-01, -2.8565e-02, -2.9307e-01,  1.9116e-01,  4.5901e-01,\n",
      "          -6.4669e-01,  2.8410e-01,  7.1452e-01,  5.5001e-01,  7.2716e-02,\n",
      "           1.0264e+00],\n",
      "         [ 1.6208e-01,  4.7036e-01, -1.7571e-01, -1.4430e-01, -4.1618e-01,\n",
      "          -2.7120e-01,  1.7485e-01,  3.4478e-01,  2.0791e-03, -8.3833e-01,\n",
      "           4.8237e-01,  1.4978e-01,  2.6961e-01,  3.1957e-01,  3.1318e-01,\n",
      "           2.4300e-01],\n",
      "         [ 2.3199e-02,  9.1282e-01,  1.2309e-01,  4.3552e-01,  3.1683e-01,\n",
      "           5.4443e-01, -4.1182e-01, -3.9750e-01, -4.6773e-01,  1.4980e-01,\n",
      "          -7.6688e-04,  1.9398e-01, -5.9607e-02,  2.7678e-01,  3.8587e-01,\n",
      "           1.0099e-01],\n",
      "         [ 3.8775e-01, -7.5004e-01,  4.4353e-01,  2.0455e-01,  5.7050e-01,\n",
      "           5.2300e-01, -5.5296e-01,  3.4047e-01, -3.5511e-01, -6.9000e-01,\n",
      "           1.3859e-01, -6.1129e-01,  2.7986e-01, -1.0584e+00, -3.4378e-01,\n",
      "          -6.7254e-01],\n",
      "         [-7.4944e-01,  1.2011e+00,  4.7504e-01, -1.4175e+00, -1.1661e-01,\n",
      "          -2.0519e-01,  4.8880e-02, -5.6190e-01,  1.6865e-01, -5.8476e-01,\n",
      "           1.5643e-01,  2.0620e-01,  3.0129e-01,  3.0515e-01,  1.5822e-01,\n",
      "           1.3580e-01],\n",
      "         [ 3.2854e-03,  8.5792e-02, -3.7273e-01, -4.3263e-01,  2.7126e-01,\n",
      "           5.5295e-01, -3.3752e-01, -3.6228e-01,  3.7946e-01, -5.6956e-01,\n",
      "           3.5850e-01,  5.0297e-01,  8.3247e-01,  2.7065e-01,  2.3051e-01,\n",
      "          -3.7021e-01],\n",
      "         [ 2.6607e-01,  7.4628e-01,  9.7758e-01,  8.5964e-01,  7.2511e-01,\n",
      "          -6.1081e-01, -6.5677e-01, -5.0406e-02, -5.2642e-02,  5.8294e-01,\n",
      "          -4.5590e-02, -3.5460e-02,  9.0733e-01,  2.4781e-01, -1.8979e-01,\n",
      "          -9.3868e-01],\n",
      "         [-9.1529e-01, -9.2379e-01,  2.2234e-01, -3.1099e-01,  3.9580e-01,\n",
      "           5.2756e-01, -4.7417e-01, -2.0447e-01, -2.5679e-01,  3.5713e-01,\n",
      "           1.9908e-01,  7.3336e-02,  6.5161e-01, -2.3829e-01,  5.5460e-01,\n",
      "          -1.9587e-01]],\n",
      "\n",
      "        [[-1.5028e-01, -6.7611e-01, -9.4847e-02,  6.0556e-02, -1.2049e-01,\n",
      "           1.1210e-01,  5.8812e-01,  4.8340e-01, -4.8511e-01,  2.8539e-01,\n",
      "           1.1188e-01, -5.7574e-01,  1.4927e-01,  2.4169e-01, -1.1611e-01,\n",
      "          -1.2201e-01],\n",
      "         [ 3.1164e-01, -9.0459e-02, -2.8066e-01,  2.6897e-01,  6.4195e-01,\n",
      "          -6.5475e-01,  1.1037e+00, -4.5296e-01, -2.1339e-02,  1.6460e-01,\n",
      "           6.7715e-01,  2.3949e-01, -4.3220e-01,  9.4793e-01,  1.7489e-01,\n",
      "          -1.5304e-01],\n",
      "         [-7.9503e-01, -1.4741e+00,  1.1253e+00,  2.7440e-01, -1.4027e+00,\n",
      "           3.7211e-01, -3.9604e-01,  8.4127e-01,  3.5312e-01,  1.4552e-01,\n",
      "           4.2781e-01,  1.1326e+00,  1.9570e-01,  4.9587e-01,  1.9671e-01,\n",
      "           7.6903e-01],\n",
      "         [-3.3248e-01, -5.9558e-01, -2.0805e-01, -5.2000e-01, -1.0317e-01,\n",
      "          -1.0147e+00,  1.2277e-01,  5.6320e-01,  2.6245e-02, -2.8960e-01,\n",
      "           4.3904e-01,  2.1655e-01, -5.1625e-01,  6.9628e-01, -7.1387e-02,\n",
      "           5.5466e-01],\n",
      "         [ 7.1868e-01, -6.9756e-01,  1.7511e-01,  4.2946e-01, -6.4692e-02,\n",
      "           2.1727e-02,  1.6995e-01,  1.0254e-01,  1.7318e-02, -3.4716e-01,\n",
      "          -2.9683e-02,  2.2608e-01, -4.8018e-01, -3.1518e-01,  2.7052e-01,\n",
      "           2.4391e-01],\n",
      "         [-1.8101e-01,  9.1307e-01,  3.3671e-01,  2.0421e-01, -3.9466e-02,\n",
      "           4.7134e-01,  2.1301e-01,  8.5801e-01,  1.5041e-01, -3.7583e-01,\n",
      "          -1.2250e-01, -7.5942e-01,  6.6617e-02, -5.8663e-01, -1.5167e-02,\n",
      "           1.1934e-01],\n",
      "         [-3.1353e-02, -6.3727e-01, -5.9223e-01,  5.9708e-01,  2.5528e-01,\n",
      "          -1.6740e-01,  1.5375e-01, -1.4879e+00,  1.2765e-01,  1.8780e-01,\n",
      "           3.5408e-01, -4.7336e-02, -2.5101e-01,  9.1024e-01, -6.3272e-01,\n",
      "          -2.5878e-01],\n",
      "         [-1.2732e+00, -6.2869e-01,  5.6168e-02, -2.5592e-03, -7.3370e-01,\n",
      "          -2.7521e-01, -1.5650e-01,  3.9314e-01, -4.1830e-01, -1.7399e+00,\n",
      "           6.3731e-01, -6.3222e-01,  4.7992e-01,  1.8370e-01,  1.0338e+00,\n",
      "          -5.4454e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
      " ---- \n",
      "tensor([[[-6.5674e-01,  2.8302e-02,  9.4470e-03, -6.9949e-01, -3.6043e-01,\n",
      "           8.3760e-01, -4.4455e-01,  1.2278e-01,  6.2761e-01, -6.2222e-01,\n",
      "           3.4833e-01,  2.4108e-01,  5.4092e-01, -2.6054e-01,  3.6119e-01,\n",
      "          -4.3574e-02],\n",
      "         [-3.9319e-01,  8.2196e-01, -7.0274e-01,  9.5429e-02, -1.2218e-01,\n",
      "          -1.5182e-01, -5.0242e-01, -4.6365e-01,  1.1758e-01,  1.4282e+00,\n",
      "          -5.8116e-01,  1.4008e-01,  9.6041e-01,  4.1002e-02, -6.2136e-01,\n",
      "          -6.3472e-01],\n",
      "         [ 2.1567e-01, -3.5065e-01,  2.1671e-03,  4.2317e-01, -2.2844e-01,\n",
      "          -7.3162e-02, -3.4118e-01,  9.6471e-01, -5.1775e-01,  9.2104e-02,\n",
      "          -5.0425e-01,  8.3885e-01,  6.1487e-01, -1.0894e-02, -5.5692e-01,\n",
      "           5.8197e-01],\n",
      "         [ 8.9999e-01, -1.2723e-01,  5.4581e-01,  4.2544e-01, -4.5128e-01,\n",
      "          -2.1242e-02,  1.7111e-01,  2.5990e-01, -9.9782e-01,  4.8897e-01,\n",
      "           1.7374e-01, -6.9986e-02, -3.1131e-01,  3.7479e-01, -1.8482e-01,\n",
      "          -6.3789e-01],\n",
      "         [ 3.3199e-02,  5.8858e-01, -4.4368e-01,  3.7748e-01, -6.8257e-01,\n",
      "          -2.7749e-01,  4.6726e-01, -1.2956e+00,  6.6032e-01,  1.6333e-01,\n",
      "          -1.7573e+00, -6.5818e-01, -2.3023e-01, -8.6169e-02, -5.9972e-03,\n",
      "           7.5729e-01],\n",
      "         [ 2.0985e-01,  4.3915e-02, -7.0198e-02,  7.2701e-02, -2.0124e-01,\n",
      "          -1.7539e+00,  1.0369e+00,  1.1635e-01,  2.9557e-01,  3.2307e-01,\n",
      "           5.0523e-01,  7.0110e-01, -2.8444e-01, -7.8443e-01,  4.7822e-01,\n",
      "          -5.1704e-01],\n",
      "         [ 6.1001e-01, -3.2841e-01, -8.5571e-01,  8.5427e-01,  7.8055e-01,\n",
      "          -4.0234e-01, -8.1832e-01, -5.5446e-02,  1.8732e-01,  2.7065e-01,\n",
      "          -7.0659e-01, -8.6369e-01,  6.9979e-01, -6.6958e-02,  2.5508e-01,\n",
      "           2.1492e-01],\n",
      "         [ 1.4591e-01,  1.3493e-01, -2.3353e-01, -4.1732e-02,  2.9277e-01,\n",
      "          -5.0801e-01,  1.1770e-01,  1.8610e-01,  1.4554e-01,  2.9240e-02,\n",
      "          -8.4698e-01,  6.1163e-01,  1.2445e+00,  1.9087e-01,  3.6944e-01,\n",
      "          -2.7448e-03]],\n",
      "\n",
      "        [[ 1.1104e+00, -8.7192e-01,  7.0978e-01,  3.6331e-01,  2.0670e-01,\n",
      "          -3.5486e-02, -3.1695e-02,  6.9234e-01, -4.1590e-01, -1.6547e+00,\n",
      "           4.3214e-01, -1.1557e+00,  7.1400e-02, -6.7660e-01,  6.0415e-01,\n",
      "          -5.9200e-01],\n",
      "         [ 3.2561e-01,  5.7866e-01,  5.4575e-01, -7.2274e-01,  1.2343e+00,\n",
      "          -1.5586e-01,  6.8699e-01, -6.3906e-01,  6.1569e-01,  2.1342e-01,\n",
      "          -9.3616e-01,  2.7811e-01,  9.5776e-01,  1.7266e-01, -1.6889e-01,\n",
      "          -1.7047e-02],\n",
      "         [-1.5634e-02, -5.4639e-01,  3.0958e-01,  3.5532e-01,  5.9885e-01,\n",
      "          -8.2791e-01, -5.9326e-01,  7.3282e-01, -4.5197e-01, -8.4692e-01,\n",
      "           5.1515e-01, -1.0304e-02, -2.4767e-01, -6.7420e-02,  1.9622e-03,\n",
      "          -8.3188e-01],\n",
      "         [-2.4959e-01,  2.7492e-01,  2.6894e-01, -3.6563e-01, -3.2585e-01,\n",
      "           3.7158e-01, -8.7898e-01,  1.5132e-01,  3.0180e-02,  3.2213e-01,\n",
      "           3.9398e-01,  6.9950e-01,  9.7176e-02,  8.0347e-02, -1.1910e-02,\n",
      "           3.9823e-01],\n",
      "         [ 3.9181e-01,  5.7756e-01,  1.3630e-01, -3.3129e-01,  3.4955e-01,\n",
      "           3.3893e-01,  2.8573e-01, -3.3917e-01,  6.8701e-01,  3.2722e-01,\n",
      "          -1.0067e+00, -5.3265e-01,  1.0750e+00,  2.7662e-01, -5.8393e-01,\n",
      "          -3.2861e-01],\n",
      "         [ 6.6613e-01,  2.1817e+00, -4.7026e-01,  5.5768e-02, -8.0701e-01,\n",
      "           6.1819e-01,  1.8163e-01, -5.4206e-01,  8.6598e-01,  9.1274e-01,\n",
      "          -1.1465e+00,  1.2842e+00,  2.2156e+00,  8.1063e-01, -1.0830e+00,\n",
      "          -1.6162e-01],\n",
      "         [-5.6865e-01,  4.0198e-01, -5.5940e-01,  2.4041e-01,  2.5784e-02,\n",
      "          -4.5127e-01,  2.0618e-01, -1.1354e-01, -5.3368e-01,  9.9677e-01,\n",
      "          -3.4785e-01,  3.3627e-02,  1.3022e-01, -3.5643e-01,  4.5948e-01,\n",
      "          -3.3823e-01],\n",
      "         [ 5.9567e-01,  2.7697e-01, -5.3694e-01,  3.8806e-01, -5.2068e-01,\n",
      "           6.3736e-02, -4.6341e-01,  1.6976e-01, -6.2182e-01, -8.5360e-01,\n",
      "           1.5969e-02, -4.1913e-01,  7.5529e-01,  3.6444e-01,  4.0385e-01,\n",
      "          -1.9791e-01]],\n",
      "\n",
      "        [[ 1.3326e+00,  1.0350e+00, -1.3503e-02, -9.2348e-01,  1.0694e+00,\n",
      "          -1.4107e-01,  4.7608e-01, -2.5034e-01, -2.9667e-02, -4.9094e-01,\n",
      "          -6.6426e-01,  9.3041e-02,  1.4563e+00,  1.4807e-01, -6.1347e-01,\n",
      "          -1.0926e+00],\n",
      "         [ 5.4338e-01, -1.9188e-01, -5.3040e-01,  6.8131e-01,  6.2352e-02,\n",
      "          -2.8209e-01, -1.6728e-02,  5.4435e-01, -3.0124e-01, -1.1855e-01,\n",
      "          -1.8416e-01, -4.8132e-01, -2.1184e-01,  2.4121e-01,  2.1798e-02,\n",
      "          -6.9178e-02],\n",
      "         [-3.3528e-01, -5.6466e-01,  6.6484e-01, -1.5190e-01,  3.6304e-01,\n",
      "           6.2404e-01, -2.4197e-01,  1.1305e+00,  1.7005e-01,  3.6276e-01,\n",
      "           8.0700e-01, -1.0924e-01,  1.9538e-01, -4.2642e-01, -6.4841e-01,\n",
      "          -2.0725e-01],\n",
      "         [-1.0337e-01,  8.0347e-02, -3.1804e-01, -1.0417e+00,  6.4425e-02,\n",
      "          -4.2446e-01,  4.8210e-01,  2.6664e-01, -5.0266e-01, -1.4787e+00,\n",
      "           1.0776e+00,  2.1790e-01, -8.7924e-01,  1.0318e-01,  1.1044e-01,\n",
      "          -8.6890e-01],\n",
      "         [ 7.3975e-01, -5.6316e-01,  6.8825e-01,  6.8188e-01,  9.2013e-01,\n",
      "          -6.6580e-01, -2.3015e-01,  3.4094e-01,  4.4395e-01,  6.7518e-01,\n",
      "           2.6042e-01,  1.4252e+00,  7.6539e-01,  2.5805e-01, -7.9161e-01,\n",
      "           7.3077e-01],\n",
      "         [ 4.9907e-02, -4.8685e-01,  2.1095e-01, -3.5810e-01,  1.2314e-01,\n",
      "           1.5951e-01,  1.7245e-01,  2.8349e-01, -2.1648e-01, -5.0059e-01,\n",
      "          -2.0210e-01,  2.4838e-01,  1.3610e-02,  1.0566e+00,  2.7065e-01,\n",
      "          -4.7702e-01],\n",
      "         [-6.4012e-01,  4.7867e-02, -2.7659e-02, -5.3705e-01,  4.5048e-01,\n",
      "           2.2384e-01, -1.1379e+00,  5.9782e-01,  1.0890e-02, -4.5584e-01,\n",
      "           7.9715e-01,  3.0061e-01,  7.8801e-01, -2.9773e-01, -1.7181e-01,\n",
      "          -7.1184e-01],\n",
      "         [ 4.1348e-02, -6.6965e-01, -4.0473e-01, -8.1760e-01, -1.4332e-01,\n",
      "          -2.2694e-01,  8.5180e-02,  3.4696e-01,  2.9030e-02,  2.2824e-01,\n",
      "           4.9848e-01,  3.6049e-01, -4.2176e-01, -5.3471e-01, -5.0211e-02,\n",
      "           1.8603e-01]],\n",
      "\n",
      "        [[ 6.2212e-04,  3.1138e-01, -7.1241e-01, -5.4445e-01,  8.2328e-01,\n",
      "          -1.6868e-01,  2.2658e-01,  4.8862e-01, -7.2207e-01,  3.6705e-01,\n",
      "          -1.3507e-01,  3.5477e-02, -4.4308e-01, -4.5602e-01, -9.0744e-01,\n",
      "          -2.2787e-01],\n",
      "         [-8.5366e-01, -1.1014e-02, -1.6077e-01,  1.7788e-03, -1.3390e-01,\n",
      "          -4.7289e-01, -2.1686e-01,  4.3677e-01,  8.0428e-01,  1.0344e+00,\n",
      "           8.8352e-03,  2.7911e-01, -7.6171e-02, -7.9940e-01,  4.4846e-01,\n",
      "           7.0971e-01],\n",
      "         [ 1.4088e+00, -4.4377e-02, -2.5436e-03,  1.2366e-01,  5.7979e-01,\n",
      "          -7.1957e-01, -5.0969e-01, -8.0928e-01, -8.9076e-02, -7.4968e-02,\n",
      "          -8.5395e-01, -1.5098e+00, -1.1381e+00, -6.0501e-02,  1.5464e-01,\n",
      "           3.2477e-01],\n",
      "         [ 1.9741e-01, -2.5031e-01, -1.2182e-01,  4.9976e-01,  2.4592e-01,\n",
      "           6.9912e-01, -4.1537e-01, -1.3993e+00,  5.9324e-01,  7.7563e-02,\n",
      "          -1.0144e+00, -8.3186e-01,  1.7011e-01, -3.2685e-01,  6.3889e-01,\n",
      "          -9.1289e-03],\n",
      "         [-1.1387e-02,  8.6315e-01,  2.5427e-01, -3.2685e-02, -1.1675e-02,\n",
      "          -6.4872e-01,  1.3967e-01, -1.2100e-01, -3.6965e-01, -3.9830e-01,\n",
      "           2.0917e-01, -4.2211e-02,  3.5471e-01, -1.4781e-02,  1.0395e-01,\n",
      "          -8.2862e-01],\n",
      "         [-3.7612e-01, -7.3518e-02, -1.1904e+00,  7.2211e-01,  2.6136e-01,\n",
      "          -3.6523e-01,  1.0752e+00, -4.8674e-01, -4.3567e-01,  1.3338e-01,\n",
      "           6.0010e-01, -3.8806e-01, -1.5267e+00, -3.4049e-01,  3.2029e-01,\n",
      "          -3.5348e-01],\n",
      "         [-3.8176e-01,  7.8970e-01,  8.1802e-01,  8.8146e-01,  7.0618e-01,\n",
      "          -6.2861e-01, -6.7371e-01, -1.7663e-01,  5.2108e-01,  6.6437e-01,\n",
      "          -8.8697e-01,  5.0958e-02,  6.5746e-01, -6.3669e-01, -8.9697e-02,\n",
      "           3.2022e-01],\n",
      "         [-3.0550e-01,  8.9354e-02, -2.3808e-01,  1.0563e+00,  3.4164e-01,\n",
      "          -9.2939e-01,  8.5246e-01,  2.3477e-02,  1.6643e-01, -1.2088e+00,\n",
      "          -2.5446e-01,  6.6724e-01, -1.5612e-01, -1.7337e-01,  1.2187e-01,\n",
      "           2.0050e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(k)\n",
    "print(' ---- ')\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1dbfaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n",
      "16 8\n"
     ]
    }
   ],
   "source": [
    "print(k.shape)\n",
    "print(k.shape[-1],k.shape[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "69853aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 8])\n"
     ]
    }
   ],
   "source": [
    "print(k.transpose(-2,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4c4147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 2, 2])\n",
      "Transposed shape: torch.Size([2, 2, 2])\n",
      "tensor([[[1, 3],\n",
      "         [2, 4]],\n",
      "\n",
      "        [[5, 7],\n",
      "         [6, 8]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example_k = torch.tensor([\n",
    "    [[1, 2],\n",
    "     [3, 4]],\n",
    "     \n",
    "    [[5, 6],\n",
    "     [7, 8]]\n",
    "])\n",
    "print(\"Original shape:\", example_k.shape)\n",
    "\n",
    "example_k_t = example_k.transpose(-2, -1)\n",
    "print(\"Transposed shape:\", example_k_t.shape)\n",
    "print(example_k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6455b55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca86b7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6de901b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) * head_size**-0.5\n",
    "print(wei.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4487122b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0449) tensor(1.0700) tensor(1.0918)\n"
     ]
    }
   ],
   "source": [
    "print(k.var(),q.var(),wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fdf8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n"
     ]
    }
   ],
   "source": [
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce34c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BatchNorm1d \n",
    "\n",
    "class LayerNorm1d:\n",
    "    def __init__(self,dim,eps=1e-5,momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        #calculate the forward pass\n",
    "        xmean = x.mean(-1,keepdim=True)\n",
    "        xvar = x.var(-1,keepdim=True)\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02c0162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LayerNorm1d object at 0x000001DF4252C390>\n"
     ]
    }
   ],
   "source": [
    "module = LayerNorm1d(1000)\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4c2fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1000])\n",
      "torch.Size([20, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(20,1000)\n",
    "y = module(x)\n",
    "# print the shape of x\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ded4fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9079, -0.8043, -0.3358,  ...,  0.3265,  0.4816,  0.2911],\n",
      "        [ 0.4661,  0.1352, -1.4794,  ...,  0.1496, -0.4081, -0.3682],\n",
      "        [-0.4649,  0.2638, -0.5113,  ...,  1.5243, -0.6974,  1.5762],\n",
      "        ...,\n",
      "        [ 1.4992, -1.6093, -1.1065,  ..., -0.0377,  1.2422,  0.4675],\n",
      "        [-0.2406, -0.2580,  0.1366,  ...,  0.6586,  1.1903, -1.9082],\n",
      "        [ 0.8679,  0.3310, -0.4543,  ...,  0.2692, -1.2094, -0.8572]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7ee121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9981, -0.8565, -0.3720,  ...,  0.3131,  0.4736,  0.2765],\n",
      "        [ 0.4814,  0.1565, -1.4288,  ...,  0.1707, -0.3769, -0.3377],\n",
      "        [-0.3677,  0.3537, -0.4136,  ...,  1.6014, -0.5978,  1.6528],\n",
      "        ...,\n",
      "        [ 1.4745, -1.6133, -1.1138,  ..., -0.0522,  1.2192,  0.4497],\n",
      "        [-0.2360, -0.2536,  0.1452,  ...,  0.6727,  1.2100, -1.9211],\n",
      "        [ 0.8652,  0.3426, -0.4217,  ...,  0.2824, -1.1566, -0.8138]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "921f0873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2339), tensor(1.0765))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0].mean(), y[:,0].std() # mean,std of one feature across all batch inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "825c9221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.8147e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,:].mean(), y[0,:].std() # mean,std of a single neuron across all of the inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91c33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ccde37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df3a684ed0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedced54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b72596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1542da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eecb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe569a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = BigramLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2028605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af442499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M parameters\n",
      "step 0: train loss 4.4112, val loss 4.4015\n",
      "step 100: train loss 2.6576, val loss 2.6632\n",
      "step 200: train loss 2.5119, val loss 2.5023\n",
      "step 300: train loss 2.4155, val loss 2.4308\n",
      "step 400: train loss 2.3519, val loss 2.3674\n",
      "step 500: train loss 2.3014, val loss 2.3224\n",
      "step 600: train loss 2.2554, val loss 2.2619\n",
      "step 700: train loss 2.2142, val loss 2.2240\n",
      "step 800: train loss 2.1605, val loss 2.1913\n",
      "step 900: train loss 2.1416, val loss 2.1511\n",
      "step 1000: train loss 2.1006, val loss 2.1305\n",
      "step 1100: train loss 2.0635, val loss 2.1142\n",
      "step 1200: train loss 2.0479, val loss 2.0957\n",
      "step 1300: train loss 2.0188, val loss 2.0636\n",
      "step 1400: train loss 2.0007, val loss 2.0459\n",
      "step 1500: train loss 1.9832, val loss 2.0359\n",
      "step 1600: train loss 1.9706, val loss 2.0427\n",
      "step 1700: train loss 1.9503, val loss 2.0282\n",
      "step 1800: train loss 1.9295, val loss 2.0238\n",
      "step 1900: train loss 1.9112, val loss 1.9839\n",
      "step 2000: train loss 1.9073, val loss 1.9943\n",
      "step 2100: train loss 1.8763, val loss 1.9677\n",
      "step 2200: train loss 1.8778, val loss 1.9619\n",
      "step 2300: train loss 1.8544, val loss 1.9550\n",
      "step 2400: train loss 1.8405, val loss 1.9402\n",
      "step 2500: train loss 1.8331, val loss 1.9409\n",
      "step 2600: train loss 1.8213, val loss 1.9326\n",
      "step 2700: train loss 1.8064, val loss 1.9390\n",
      "step 2800: train loss 1.7905, val loss 1.9274\n",
      "step 2900: train loss 1.7929, val loss 1.9324\n",
      "step 3000: train loss 1.7830, val loss 1.9122\n",
      "step 3100: train loss 1.7725, val loss 1.9017\n",
      "step 3200: train loss 1.7542, val loss 1.8878\n",
      "step 3300: train loss 1.7571, val loss 1.8983\n",
      "step 3400: train loss 1.7622, val loss 1.8949\n",
      "step 3500: train loss 1.7527, val loss 1.8979\n",
      "step 3600: train loss 1.7436, val loss 1.8899\n",
      "step 3700: train loss 1.7407, val loss 1.8860\n",
      "step 3800: train loss 1.7330, val loss 1.8872\n",
      "step 3900: train loss 1.7235, val loss 1.8719\n",
      "step 4000: train loss 1.7087, val loss 1.8610\n",
      "step 4100: train loss 1.7189, val loss 1.8514\n",
      "step 4200: train loss 1.7145, val loss 1.8575\n",
      "step 4300: train loss 1.7120, val loss 1.8458\n",
      "step 4400: train loss 1.6969, val loss 1.8605\n",
      "step 4500: train loss 1.6954, val loss 1.8470\n",
      "step 4600: train loss 1.6951, val loss 1.8358\n",
      "step 4700: train loss 1.6894, val loss 1.8340\n",
      "step 4800: train loss 1.6838, val loss 1.8454\n",
      "step 4900: train loss 1.6770, val loss 1.8313\n",
      "step 4999: train loss 1.6809, val loss 1.8288\n",
      "\n",
      "When thy bridlewick to on, by made of boay toe.\n",
      "Soven'd Muchainants: manthmen's hath be?\n",
      "\n",
      "MEXETIO:\n",
      "Butway, my fearst, when must of the office come milknowly,\n",
      "We mireets, hein ladist in overs, and Will.\n",
      "\n",
      "DUKE OF AUMElisHody:\n",
      "So.\n",
      "Maste conviry: there's speak yet lets.\n",
      "In Badoated the homany would that\n",
      "monting to dryevickle's them son,\n",
      "The highnes poor of my lord: kindnest first of; worst must with aledgeth,\n",
      "Madarry, I'll my fright, astick is wards.\n",
      "With Erefore of the keear teyorry to-changed vown, neet noke mary.\n",
      "You will bream son, and see-specure the men.\n",
      "\n",
      "CLAYCENTES:\n",
      "Whes thy welcome, will.\n",
      "\n",
      "MENENIUS:\n",
      "I thas lord\n",
      "IsA speech pein, thou ever'd helply to-maduty!\n",
      "\n",
      "KING EDWARD IV:\n",
      "Tie so not his rare'd, and yet't Clangs\n",
      "The heart, is deeve, moxer any\n",
      "the beares against the war soul.\n",
      "\n",
      "Clomenger:\n",
      "We so lack, my is and their subject.\n",
      "\n",
      "KING HENRY Gently Caltenry:\n",
      "But to meing the shopen eyes man iport,\n",
      "Thesubject and hers, speepless keeps no humant pribect watch time wout\n",
      "in forcesy excents enour and breweep,\n",
      "For I Quest farewell. Buckes hide priveftand, and that's orn against,\n",
      "mere thinks so mentleming think to hight:\n",
      "How wouldd chial frieng! abhease Intreatience,\n",
      "And pray ince anybenk to dolament!\n",
      "\n",
      "FLUCENIUS:\n",
      "I brothapine.\n",
      "\n",
      "DUKE OUCHIOLINGBEY:\n",
      "Godo your Henener morrult; look.\n",
      "The oftress of my know the throught?\n",
      "\n",
      "Second Norbehomies his; do belothy done him, my lied thy begrace.\n",
      "\n",
      "QUEEN OFOLINGSEY:\n",
      "How far elswered; I the and unto may's from your gelpievenss.\n",
      "\n",
      "IELEA:\n",
      "Marrow old the elsest since,\n",
      "He use thembrars, evas; for but of a-hathere Clant.\n",
      "\n",
      "PLAULINCE:\n",
      "My farewirds is above wall prequar'd shade brawfy him.\n",
      "\n",
      "LEONTES:\n",
      "O,-marrither arwhice armIast,\n",
      "Behold comforh, sinmorast of gracition.\n",
      "But Helsernous the gracely, girt mant,\n",
      "And rachive! with arking, would talk we twreet withofare?\n",
      "But I have burse lipe insurelict?\n",
      "\n",
      "CLESTER:\n",
      "Norse, and was walk: no with say, thy proud,\n",
      "They armnsent, Joar atune Edwall\n",
      "on the Riparling: In in shall'd for a diess them here he woe!\n",
      "\n",
      "\n",
      "MENE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c74de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
